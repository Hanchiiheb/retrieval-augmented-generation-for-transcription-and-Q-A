{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# This is the YouTube video we're going to use.\n",
    "#YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\"\n",
    "#YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=NiKtZgImdlY\"\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=ufQEqi4LUZ4z\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'During the COVID-19 pandemic, which began in 2020 and continued into the 2021 season, there was no MLB World Series played. The pandemic caused significant disruptions to the baseball season, including canceled games, modified schedules, and changes to the postseason format. As a result, there was no MLB team that won the World Series during this time period.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "model = OllamaLLM(model=\"llama2\")\n",
    "\n",
    "chain = model | parser\n",
    "\n",
    "\n",
    "chain.invoke(\"What MLB team won the World Series during the COVID-19 pandemic?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: \\nAnswer the question based on the context below. If you can\\'t \\nanswer the question, reply \"I don\\'t know\".\\n\\nContext: Mary\\'s sister is Susana\\n\\nQuestion: Who is Mary\\'s sister?\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't \n",
    "answer the question, reply \"I don't know\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "prompt.format(context=\"Mary's sister is Susana\", question=\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Of course! Based on the context provided, Mary's sister is Susana.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | model | parser\n",
    "chain.invoke({\n",
    "    \"context\": \"Mary's sister is Susana\",\n",
    "    \"question\": \"Who is Mary's sister?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate {answer} to {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nSure! Here\\'s the translation of \"Based on the context provided, Mary has only one sister, which is Susana. Therefore, the answer to the question is \\'1\\'\" in Spanish:\\n\\n\"Based on the context provided, Mar√≠a solo tiene una hermana, que es Susana. Por lo tanto, la respuesta a la pregunta es \\'1\\'.\"\\n\\nI hope this helps! Let me know if you have any other questions.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "translation_chain = (\n",
    "    {\"answer\": chain, \"language\": itemgetter(\"language\")} | translation_prompt | model | parser\n",
    ")\n",
    "\n",
    "translation_chain.invoke(\n",
    "    {\n",
    "        \"context\": \"Mary's sister is Susana. She doesn't have any more siblings.\",\n",
    "        \"question\": \"How many sisters does Mary have?\",\n",
    "        \"language\": \"Spanish\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytubefix import YouTube\n",
    "from pytubefix.cli import on_progress\n",
    " \n",
    "#url = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\"\n",
    "#url = \"https://www.youtube.com/watch?v=NiKtZgImdlY\"\n",
    "url = \"https://www.youtube.com/watch?v=ufQEqi4LUZ4z\"\n",
    "\n",
    " \n",
    "yt = YouTube(url, on_progress_callback = on_progress)\n",
    "print(yt.title)\n",
    " \n",
    "ys = yt.streams.get_highest_resolution()\n",
    "ys.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Load the downloaded video\n",
    "#video = VideoFileClip(\"Andrej Karpathy Tesla AI, Self-Driving, Optimus, Aliens, and AGI  Lex Fridman Podcast #333.mp4\")\n",
    "#video = VideoFileClip(\"The danger of silence  Clint Smith  TED.mp4\")\n",
    "video = VideoFileClip(\"Mindset Reset Take Control of Your Mental Habits  The Mel Robbins Podcast.mp4\")\n",
    "\n",
    "# Extract audio and save it as an MP3 file\n",
    "\n",
    "#audio_path = \"c:\\\\Users\\\\ahmed\\\\RAGTRANS\\\\audio.mp3\"\n",
    "audio_path = \"C:\\\\Users\\\\ahmed\\Videos\\\\RAGTRANS\\\\podcast1H20.mp3\"\n",
    "\n",
    "\n",
    "video.audio.write_audiofile(audio_path)\n",
    "\n",
    "print(f\"Audio extracted and saved to: {audio_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import os\n",
    "\n",
    "# Load the Whisper model\n",
    "whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "# Use raw string literals for the audio file path\n",
    "#audio_path = r\"c:\\Users\\ahmed\\RAGTRANS\\audio.mp3\"\n",
    "#audio_path = r\"C:\\\\Users\\\\ahmed\\Videos\\\\RAGTRANS\\\\test.mp3\"\n",
    "audio_path = r\"C:\\\\Users\\\\ahmed\\Videos\\\\RAGTRANS\\\\podcast1H20.mp3\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(audio_path):\n",
    "    print(f\"Audio file found at: {audio_path}\")\n",
    "    \n",
    "    # Transcribe the audio\n",
    "    try:\n",
    "        transcription = whisper_model.transcribe(audio_path, fp16=False)[\"text\"].strip()\n",
    "        \n",
    "        # Print the transcription\n",
    "        print(\"Transcription: \", transcription)\n",
    "\n",
    "        # Save the transcription to a text file\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while transcribing: {e}\")\n",
    "else:\n",
    "    print(\"Audio file not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we've got a crazy cool topic. We are talking about mindset. Your mind is either working for\n",
      "either working for you or against you. That's what it's doing. So whether you're listening to this\n",
      "listening to this episode because you struggle right now with overthinking or feeling unworthy or\n",
      "feeling unworthy or maybe you have a really positive outlook but you just want to level up. You\n",
      "to level up. You want to play a bigger game. That's where I am right now. So today you and I are\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Read the transcription file (assuming it's in the current directory)\n",
    "with open(\"transcription.txt\", \"r\") as file:\n",
    "    transcription_text = file.read()\n",
    "\n",
    "# Create a Document object\n",
    "document = Document(page_content=transcription_text)\n",
    "\n",
    "# Initialize the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=100, chunk_overlap=20)\n",
    "\n",
    "# Split the transcription into chunks\n",
    "chunks = text_splitter.split_documents([document])\n",
    "\n",
    "# Display the first 5 chunks\n",
    "for chunk in chunks[:5]:\n",
    "    print(chunk.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today we've got a crazy cool topic. We are talking about mindset. Your mind is either working for you or against you. That's what it's doing. So whether you're listening to this episode because you struggle right now with overthinking or feeling unworthy or maybe you have a really positive outlook but you just want to level up. You want to play a bigger game. That's where I am right now. So today you and I are going to get serious about making your mind work for you. Hey, it's your friend Mel and welcome to a mind bending and really cool episode of the Mel Robbins podcast. Okay, I wanted to just start today by saying thank you. Thank you, thank you, thank you to you. I often say that the Mel Robbins podcast is not my podcast, it's our podcast because this is a conversation between you and me and I wanted to start off by saying thank you because about 90 seconds ago, I got word that you have voted the Mel Robbins podcast as the most inspirational podcast of 2022. We have won the\n",
      "We have won the listeners choice award for the most inspiring podcast of 2022. That is a huge deal because we just launched two and a half months ago. So from the bottom of my heart on behalf of my team, I just wanted to thank you. I wanted to thank you for showing up for listening, for sharing these episodes with friends and family members, for giving us feedback, for asking questions, for submitting topic ideas. This podcast is changing people's lives and it is inspiring and empowering people around the world because of you. So thank you. And if you're brand new to the Mel Robbins podcast and this amazing, energizing group of people that listen to this podcast, I want to say welcome. I'm Mel Robbins, I'm a New York Times bestselling author and I'm one of the most trusted experts in the world on behavior change and motivation. And today we've got a crazy cool topic. We are talking about mindset and before we jump into the science and the cool tactics that you're going to be able to\n",
      "going to be able to apply to your life to change your mindset, I want to just remind you that this episode is part of a month long series that we are doing here on the Mel Robbins podcast about the building blocks and the research that you need to know in order to create a better life. Here's the simple truth about your mindset. Your mind is either working for you or against you. That's what it's doing. And so by the end of today's episode, there's going to be a couple things to go down. First of all, you are going to understand that you have the power to reprogram your mind. That's right. You can take simple steps and you can practice them every day to train your mind to work for you. I'm also going to prove to you today using very simple science that your mind is trying to help you. It doesn't know any better if it's working against you. And when you can identify the way that you want to feel or what you want to do with your life, you can change your mindset to help you. And when\n",
      "help you. And when you do that, here's what's super cool. It improves the day-to-day experience of your life and it changes what it's like to be in your head. So whether you're listening to this episode because you struggle right now with overthinking or feeling unworthy or maybe you have a really positive outlook, but you just want to level up. You want to play a bigger game. That's where I am right now. I am so ready to take a bigger swing to knock it out of the park this year and the mindset and creating a more powerful mindset. That is a tool in your arsenal to help you achieve anything that you want. So today you and I are going to get serious about making your mind work for you. And I want to start us off with a question from a listener named Brandi. Hi there, Mel. My name is Brandi. How do I stop the spiral of negative thoughts and feelings? I really want to reset and start embracing a happier life. I just don't know where to start. I hope you can help. Brandi, I am so happy\n",
      "I am so happy that you asked this question because we have received thousands of versions of this question. And I'm also kind of thrilled. I picked your question in particular because you use the word reset. And today I am going to teach you how to give yourself a mindset reset. And I'm going to explain what a mindset reset is, the simple step, the simple steps to doing it. It's all going to make sense in a couple minutes. But I want to give you a preview so that as we step into the process of giving yourself a reset mentally that you have a baseline understanding. So here's a preview of what we're going to talk about. You have a filter in your brain. And I'm going to teach you using science and neuroscience, how to use this filter that's already in your brain to your advantage. And everything that I'm going to teach you, you can put to practice immediately. And what I love so much about this conversation that we're about to have is that you may even experience an immediate change.\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Step 1: Read the transcription file\n",
    "with open(\"transcription.txt\", \"r\") as file:\n",
    "    transcription_text = file.read()\n",
    "\n",
    "# Step 2: Create a Document object with the transcription content\n",
    "document = Document(page_content=transcription_text, metadata={'source': 'transcription.txt'})\n",
    "\n",
    "# Step 3: Initialize the text splitter with a chunk size of 1000 characters and 20 characters overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "# Step 4: Split the transcription into chunks\n",
    "documents = text_splitter.split_documents([document])\n",
    "\n",
    "# Step 5: Display the first few chunks\n",
    "for chunk in documents[:5]:\n",
    "    print(chunk.page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 4096\n",
      "[0.02356694, 0.005193902, 0.0052631935, 0.031144299, 0.005877835, -0.017635036, 0.0054636756, 0.0056269797, -0.0033483005, -0.005124399]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the Llama2 embedding model\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "embeddings = OllamaEmbeddings(\n",
    "    model=\"llama2\",\n",
    ")\n",
    "# Embed a query using Llama2\n",
    "embedded_query = embeddings.embed_query(\"Who is Mary's sister?\")\n",
    "\n",
    "# Output the length and the first 10 elements of the embedding\n",
    "print(f\"Embedding length: {len(embedded_query)}\")\n",
    "print(embedded_query[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = embeddings.embed_query(\"Mary's sister is Susana\")\n",
    "sentence2 = embeddings.embed_query(\"Pedro's mother is a teacher\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0030565065691788122, 0.5271359943533441)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "query_sentence1_similarity = cosine_similarity([embedded_query], [sentence1])[0][0]\n",
    "query_sentence2_similarity = cosine_similarity([embedded_query], [sentence2])[0][0]\n",
    "\n",
    "query_sentence1_similarity, query_sentence2_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.13\n"
     ]
    }
   ],
   "source": [
    "import langchain_community\n",
    "print(langchain_community.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "vectorstore1 = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"Mary's sister is Susana\",\n",
    "        \"John and Tommy are brothers\",\n",
    "        \"Patricia likes white cars\",\n",
    "        \"Pedro's mother is a teacher\",\n",
    "        \"Lucia drives an Audi\",\n",
    "        \"Mary has two siblings\",\n",
    "    ],\n",
    "    embedding=embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={}, page_content=\"Pedro's mother is a teacher\"),\n",
       "  0.5271360416397188),\n",
       " (Document(metadata={}, page_content='Patricia likes white cars'),\n",
       "  0.5088044373421162),\n",
       " (Document(metadata={}, page_content='Mary has two siblings'),\n",
       "  0.48031196976187845)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore1.similarity_search_with_score(query=\"Who is Mary's sister?\", k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content=\"Pedro's mother is a teacher\"),\n",
       " Document(metadata={}, page_content='Patricia likes white cars'),\n",
       " Document(metadata={}, page_content='Mary has two siblings'),\n",
       " Document(metadata={}, page_content='John and Tommy are brothers')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever1 = vectorstore1.as_retriever()\n",
    "retriever1.invoke(\"Who is Mary's sister?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='Patricia likes white cars'),\n",
       "  Document(metadata={}, page_content='Mary has two siblings'),\n",
       "  Document(metadata={}, page_content=\"Pedro's mother is a teacher\"),\n",
       "  Document(metadata={}, page_content='John and Tommy are brothers')],\n",
       " 'question': \"What color is Patricia's car?\"}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "setup = RunnableParallel(context=retriever1, question=RunnablePassthrough())\n",
    "setup.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know. The context you provided does not provide enough information to determine the color of Patricia's car.\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = setup | prompt | model | parser\n",
    "chain.invoke(\"What color is Patricia's car?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know the answer to your question as there is no information in the provided context about Lucia or her car.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What car does Lucia drive?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
